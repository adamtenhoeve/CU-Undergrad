{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #4\n",
    "\n",
    "**Due by midnight on Friday February 15, 2019**. Complete all of the following problems. Ideally, the theoretical problems should be answered in a Markdown cell directly underneath the question. If you don't know LaTex/Markdown, you may submit separate handwritten solutions to the theoretical problems. Please do not turn in messy work. Computational problems should be completed in this notebook (using the R kernel is preferred). Computational questions may require code, plots, analysis, interpretation, etc. Working in small groups is allowed, but it is important that you make an effort to master the material and hand in your own work. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Adam Ten Hoeve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Theoretical Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem A.1\n",
    "\n",
    "For each of the following models, decide whether one could use linear least squares to estimate the model parameters. Explain your answer.\n",
    "\n",
    "1.  $\\displaystyle Y_i = \\beta_0 + \\beta_1\\log(X_i)$\n",
    "2. $\\displaystyle Y_i = \\beta_0 + e^{\\beta_1X_i}$\n",
    "3.  $\\displaystyle Y_i = \\beta_0 + \\beta_1\\sin(X_i)$\n",
    "4.  $\\displaystyle Y_i = \\beta_0 + \\sin(\\beta_1X_i)$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Yes. Although the feature X is not linear, the model is linear with respect to the parameters $\\beta_0$ and $\\beta_1$. Because of this, the model can be treated as a system of linear equations and linear least squares can be applied.\n",
    "2. Yes. The model can be transformed to linear: $ Y_i = \\beta_0 + e^{\\beta_1X_i} = \\beta_0 + e^{\\beta_1}e^{X_i} = \\beta_0 + ke^{X_i}$. From here, all of the weights are linear coefficients so the model can be estimated using linear least squares.\n",
    "3. Yes. Similar to the reason for number 1, all of the coefficients are linear so the model can be treated as a system of linear equations and linear least squares can be a good estimate.\n",
    "4. No. Because the $\\beta_1$ term is within the sin() and can not be pulled out, the parameters are not linear and linear least squares would not work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem A.2\n",
    "\n",
    "#### Prove that $TSS = RSS + ESS$. Recall that $TSS$ is the total sum of squares, $RSS$ is the residual sum of squares, and $ESS$ is the explained (or model or regression) sum of squares. (HINT: you might start with TSS and add a fancy form of 1 somewhere.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "    TSS =& \\sum_{i=1}^n (y_i - \\bar{y})^2 \\\\ \n",
    "    =& \\sum_{i=1}^n (y_i - \\hat{y}_i + \\hat{y}_i - \\bar{y})^2 \\\\\n",
    "    =& \\sum_{i=1}^n \\Big[ (y_i - \\bar{y}_i)^2 + (\\hat{y}_i - \\bar{y})^2 + 2(y_i - \\hat{y}_i)(\\hat{y}_i - \\bar{y}) \\Big] \\\\\n",
    "    =& \\sum_{i=1}^n (y_i - \\bar{y}_i)^2 + \\sum_{i=1}^n (\\hat{y}_i - \\bar{y})^2 + 2\\sum_{i=1}^n(y_i - \\hat{y}_i)(\\hat{y}_i - \\bar{y}) \\\\\n",
    "    =& ESS + RSS + 2\\sum_{i=1}^n(y_i - \\hat{y}_i)(\\hat{y}_i - \\bar{y})\n",
    "\\end{align*}\n",
    "$$\n",
    "From this point, we must prove $\\sum_{i=1}^n(y_i - \\hat{y}_i)(\\hat{y}_i - \\bar{y}) = 0$ for the equality to be true. Recall that $\\hat{y} = \\beta_0 + \\beta_1x_i$ in the SLR case, which we will use for simplicity.\n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "0 &= \\sum_{i=1}^n(y_i - \\hat{y}_i)(\\hat{y}_i - \\bar{y}) \\\\\n",
    "&= \\sum_{i=1}^n \\hat{y}_i(y_i - \\hat{y}_i) - \\sum_{i=1}^n \\bar{y}(y_i - \\hat{y}_i) \\\\\n",
    "&= \\sum_{i=1}^n (\\beta_0 + \\beta_1x_i)(y_i - \\hat{y}_i) - \\bar{y} \\sum_{i=1}^n (y_i - \\hat{y}_i) \\\\\n",
    "&= \\beta_0\\sum_{i=1}^n (y_i - \\hat{y}_i) + \\beta_1\\sum_{i=1}^n x_i(y_i - \\hat{y}_i) - \\bar{y} \\sum_{i=1}^n (y_i - \\hat{y}_i) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We want to find $\\beta_0$ and $\\beta_1$ that minimize the sum. Therefor we can take the partial derivatives with respect to each variable and set it equal to zero. Let's start with $\\beta_0$.\n",
    "\n",
    "$$ 0 = \\frac{\\partial}{\\partial\\beta_0}\\Big( \\beta_0\\sum_{i=1}^n (y_i - \\hat{y}_i) + \\beta_1\\sum_{i=1}^n x_i(y_i - \\hat{y}_i) - \\bar{y} \\sum_{i=1}^n (y_i - \\hat{y}_i) \\Big) = \\sum_{i=1}^n y_i - \\hat{y}_i$$\n",
    "\n",
    "This makes sense as the sum of the residuals should be 0. Now let's take the derivative with respect to $\\beta_1$.\n",
    "\n",
    "$$ 0 = \\frac{\\partial}{\\partial\\beta_1}\\Big( \\beta_0\\sum_{i=1}^n (y_i - \\hat{y}_i) + \\beta_1\\sum_{i=1}^n x_i(y_i - \\hat{y}_i) - \\bar{y} \\sum_{i=1}^n (y_i - \\hat{y}_i) \\Big) = \\sum_{i=1}^n x_i(y_i - \\hat{y}_i)$$\n",
    "\n",
    "And finally knowing that the sum of the residuals is zero gives us our final answer:\n",
    "\n",
    "$$ \\sum_{i=1}^n(y_i - \\hat{y}_i)(\\hat{y}_i - \\bar{y}) = \\beta_0\\sum_{i=1}^n (y_i - \\hat{y}_i) + \\beta_1\\sum_{i=1}^n x_i(y_i - \\hat{y}_i) - \\bar{y} \\sum_{i=1}^n (y_i - \\hat{y}_i) = 0 $$\n",
    "\n",
    "Therefor:\n",
    "\n",
    "$$ TSS = ESS + RSS $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem A.3\n",
    "\n",
    "When there is no good reason to believe that $Y$ and $X$ are correlated, instead of fitting a simple linear regression model to your data, we might fit $Y = \\beta_0 + \\varepsilon$. In fact, when we compute $R^2$ or conduct the full F-test, we are comparing a given MLR model to the model $Y = \\beta_0 + \\varepsilon$.\n",
    "\n",
    "\n",
    "#### (a) Generally, what is one advantage and one disadvantage of the mean as a measure of center?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One advantage of the mean is that, with symmetric data, it accureatley and efficiently finds the center of the data. One disadvanged is that the mean can be heavily influenced by skew and outliers. For examle, if we have 9 data points with values around ~10, then 1 outlier data point with value of 1000, then the mean is $\\sim 109$, which does not accurately reflect the \"center\" of the majority of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)  Generally, what is one advantage and one disadvantage of the median as a measure of center?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opposite of the mean, the median is still a good measure of center even when the data has outliers as it is not affected by the size of the data, only the order. However, the median can not be used if many statistical calculations or tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)  Show that the ordinary least squares estimate of $\\beta_0$ is $\\widehat{\\beta}_0 = \\bar{y}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "    RSS &= \\sum_{i=1}^n (Y_i - \\hat{Y-i})^2  \\\\\n",
    "    &= \\sum_{i=1}^n (Y_i - \\beta_0 + \\epsilon_i)^2 \\\\\n",
    "    &= (Y_1 - \\beta_0 + \\epsilon)^2 + ... + (Y_n - \\beta_0 + \\epsilon_i) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Recall that to get our estimate $\\hat{\\beta_0}$, we want to minimize the RSS. To do so, we will take the derivative with respect to $\\beta_0$ and set it equal to zero.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    0 &= 2(Y_1 - \\beta_0 + \\epsilon)(-1) + ... + 2(Y_n - \\beta_0 + \\epsilon_i)(-1) \\\\\n",
    "    0 &= -2 \\sum_{i=1}^n Y_i - \\beta_0 - \\epsilon_i \\\\\n",
    "    0 &= \\sum_{i=1}^n Y_i - \\sum_{i=1}^n \\beta_0 - \\sum_{i=1}^n \\epsilon_i \\\\\n",
    "    0 &= \\sum_{i=1}^n Y_i - n\\beta_0 \\\\\n",
    "    \\beta_0 &= \\frac{1}{n} \\sum_{i=1}^n Y_i \\\\\n",
    "    \\hat{\\beta_0} &= \\bar{Y}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "In the above equation, note that $\\sum_{i=1}^n \\epsilon_i = 0$ as the sum of the residuals is zero, assuming that the model is the line of best fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) (**Graduate Students only**) Show that the least absolute value estimate of $\\beta_0$, found by minimizing $\\sum^n_{i=1}|y_i-\\beta_0|$, is the sample median, $\\tilde{y}$. (For the linear algebra lovers: the minimization problem in least squares is performed using the 2-norm; this problem is performed using the 1-norm.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem A.4\n",
    "\n",
    "Consider the following two models:\n",
    "\n",
    "\\begin{equation}\n",
    "Y_i = \\beta_0 + \\beta_1X_{i,1} + ... + \\beta_{p}X_{i,p} + \\varepsilon_i, \\,\\,\\,\\,\\,\\,\\, \\text{(M1)}\n",
    "\\end{equation}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{equation}\n",
    "Y_i = \\beta_0 + \\beta_1X_{i,1} + ... + \\beta_{p}X_{i,p} + \\beta_{p+1}X_{i,(p+1)} + \\varepsilon_i. \\,\\,\\,\\,\\,\\,\\, \\text{(M2)}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Show that $R^2$ for M2 is always greater than $R^2$ for M1, no matter what the added predictor is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start out, let's look at the equation for the coefficient of determination $R^2$.\n",
    "\n",
    "$$ R^2 = 1 - \\dfrac{RSS}{TSS} = 1 - \\dfrac{\\sum_{i=1}^n (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2}$$\n",
    "\n",
    "For M1:\n",
    "$$ R^2_{M1} = 1 - \\dfrac{\\sum_{i=1}^n (y_i - (\\beta_0 + \\beta_1X_{i,1} + ... + \\beta_pX_{i,p} + \\epsilon_i))^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2} $$\n",
    "\n",
    "For M2:\n",
    "$$ R^2_{M2} = 1 - \\dfrac{\\sum_{i=1}^n (y_i - (\\beta_0 + \\beta_1X_{i,1} + ... + \\beta_pX_{i,p} + \\beta_{p+1}X_{i,(p+1)} + \\epsilon_i))^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2} $$\n",
    "\n",
    "Now we can find a ratio of these two terms. If $\\dfrac{R^2_{M2}}{R^2_{M1}} > 1$, then we know that the $R^2$ value will always be greater than the other. Before we start, we should note that to get the largest total $R^2$ value, we want to minimize the $\\frac{RSS}{TSS}$ term.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    1 &< \\dfrac{R^2_{M2}}{R^2_{M1}} \\\\\n",
    "    R^2_{M1} &< R^2_{M2} \\\\\n",
    "   1 - \\dfrac{\\sum_{i=1}^n (y_i - (\\beta_0 + \\beta_1X_{i,1} + ... + \\beta_pX_{i,p} + \\epsilon_i))^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2} &< 1 - \\dfrac{\\sum_{i=1}^n (y_i - (\\beta_0 + \\beta_1X_{i,1} + ... + \\beta_pX_{i,p} + \\beta_{p+1}X_{i,(p+1)} + \\epsilon_i))^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2} \\\\\n",
    "   \\sum_{i=1}^n (y_i - (\\beta_0 + \\beta_1X_{i,1} + ... + \\beta_pX_{i,p} + \\beta_{p+1}X_{i,(p+1)} + \\epsilon_i))^2 &< \\sum_{i=1}^n (y_i - (\\beta_0 + \\beta_1X_{i,1} + ... + \\beta_pX_{i,p} + \\epsilon_i))^2 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "I'm not sure how to mathemicatically prove the rest of this but I will go through the intution behind it. We can see that the summations are basically describing distances between two points, one point being the true value $y$ and one being the estimated value $\\hat{y}$. The first model does not account for the $p+1$ parameter, which actual means that it's assigning $\\beta_{p+1} = 0$. The second model does account for the $p+1$ parameter, meaning that $\\beta_{p+1}$ may or may not be 0. If $\\beta_{p+1} = 0$ for both models, then they will have the same $R^2$. If $\\beta_{p+1} \\ne 0$ then (assuming it is the most optimal model) some of the variance of the data is being explained that is not being explained in the first model. Because of this, no matter the value of $\\beta_{p+1}$, the unexplained variation of the model $(\\frac{RSS}{TSS})$ will be less and the $R^2$ value will increase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Computational Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem B.1\n",
    "\n",
    "#### (a) Load the ${\\tt prostate}$ data into R using the faraway package. The prostate data frame has 97 rows and 9 columns. It comes from a study on 97 men with prostate cancer who were due to receive a radical prostatectomy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>lcavol</th><th scope=col>lweight</th><th scope=col>age</th><th scope=col>lbph</th><th scope=col>svi</th><th scope=col>lcp</th><th scope=col>gleason</th><th scope=col>pgg45</th><th scope=col>lpsa</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>-0.5798185</td><td>2.7695    </td><td>50        </td><td>-1.386294 </td><td>0         </td><td>-1.38629  </td><td>6         </td><td> 0        </td><td>-0.43078  </td></tr>\n",
       "\t<tr><td>-0.9942523</td><td>3.3196    </td><td>58        </td><td>-1.386294 </td><td>0         </td><td>-1.38629  </td><td>6         </td><td> 0        </td><td>-0.16252  </td></tr>\n",
       "\t<tr><td>-0.5108256</td><td>2.6912    </td><td>74        </td><td>-1.386294 </td><td>0         </td><td>-1.38629  </td><td>7         </td><td>20        </td><td>-0.16252  </td></tr>\n",
       "\t<tr><td>-1.2039728</td><td>3.2828    </td><td>58        </td><td>-1.386294 </td><td>0         </td><td>-1.38629  </td><td>6         </td><td> 0        </td><td>-0.16252  </td></tr>\n",
       "\t<tr><td> 0.7514161</td><td>3.4324    </td><td>62        </td><td>-1.386294 </td><td>0         </td><td>-1.38629  </td><td>6         </td><td> 0        </td><td> 0.37156  </td></tr>\n",
       "\t<tr><td>-1.0498221</td><td>3.2288    </td><td>50        </td><td>-1.386294 </td><td>0         </td><td>-1.38629  </td><td>6         </td><td> 0        </td><td> 0.76547  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllll}\n",
       " lcavol & lweight & age & lbph & svi & lcp & gleason & pgg45 & lpsa\\\\\n",
       "\\hline\n",
       "\t -0.5798185 & 2.7695     & 50         & -1.386294  & 0          & -1.38629   & 6          &  0         & -0.43078  \\\\\n",
       "\t -0.9942523 & 3.3196     & 58         & -1.386294  & 0          & -1.38629   & 6          &  0         & -0.16252  \\\\\n",
       "\t -0.5108256 & 2.6912     & 74         & -1.386294  & 0          & -1.38629   & 7          & 20         & -0.16252  \\\\\n",
       "\t -1.2039728 & 3.2828     & 58         & -1.386294  & 0          & -1.38629   & 6          &  0         & -0.16252  \\\\\n",
       "\t  0.7514161 & 3.4324     & 62         & -1.386294  & 0          & -1.38629   & 6          &  0         &  0.37156  \\\\\n",
       "\t -1.0498221 & 3.2288     & 50         & -1.386294  & 0          & -1.38629   & 6          &  0         &  0.76547  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "lcavol | lweight | age | lbph | svi | lcp | gleason | pgg45 | lpsa | \n",
       "|---|---|---|---|---|---|\n",
       "| -0.5798185 | 2.7695     | 50         | -1.386294  | 0          | -1.38629   | 6          |  0         | -0.43078   | \n",
       "| -0.9942523 | 3.3196     | 58         | -1.386294  | 0          | -1.38629   | 6          |  0         | -0.16252   | \n",
       "| -0.5108256 | 2.6912     | 74         | -1.386294  | 0          | -1.38629   | 7          | 20         | -0.16252   | \n",
       "| -1.2039728 | 3.2828     | 58         | -1.386294  | 0          | -1.38629   | 6          |  0         | -0.16252   | \n",
       "|  0.7514161 | 3.4324     | 62         | -1.386294  | 0          | -1.38629   | 6          |  0         |  0.37156   | \n",
       "| -1.0498221 | 3.2288     | 50         | -1.386294  | 0          | -1.38629   | 6          |  0         |  0.76547   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  lcavol     lweight age lbph      svi lcp      gleason pgg45 lpsa    \n",
       "1 -0.5798185 2.7695  50  -1.386294 0   -1.38629 6        0    -0.43078\n",
       "2 -0.9942523 3.3196  58  -1.386294 0   -1.38629 6        0    -0.16252\n",
       "3 -0.5108256 2.6912  74  -1.386294 0   -1.38629 7       20    -0.16252\n",
       "4 -1.2039728 3.2828  58  -1.386294 0   -1.38629 6        0    -0.16252\n",
       "5  0.7514161 3.4324  62  -1.386294 0   -1.38629 6        0     0.37156\n",
       "6 -1.0498221 3.2288  50  -1.386294 0   -1.38629 6        0     0.76547"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(faraway)\n",
    "head(prostate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Conduct MLR with lpsa as the response and all of the other variables as predictors. Compute the 90% and 95% confidence intervals for the parameter associated with the age variable. Using these intervals, what could we have deduced about the p-value for age in the regression summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>2.5 %</th><th scope=col>97.5 %</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>prostate$age</th><td>-0.04184062</td><td>0.002566267</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & 2.5 \\% & 97.5 \\%\\\\\n",
       "\\hline\n",
       "\tprostate\\$age & -0.04184062 & 0.002566267\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 2.5 % | 97.5 % | \n",
       "|---|\n",
       "| prostate$age | -0.04184062 | 0.002566267 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "             2.5 %       97.5 %     \n",
       "prostate$age -0.04184062 0.002566267"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>5 %</th><th scope=col>95 %</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>prostate$age</th><td>-0.0382102  </td><td>-0.001064151</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & 5 \\% & 95 \\%\\\\\n",
       "\\hline\n",
       "\tprostate\\$age & -0.0382102   & -0.001064151\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 5 % | 95 % | \n",
       "|---|\n",
       "| prostate$age | -0.0382102   | -0.001064151 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "             5 %        95 %        \n",
       "prostate$age -0.0382102 -0.001064151"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lmod1 = lm(prostate$lpsa ~ prostate$lcavol + prostate$lweight + prostate$age + prostate$lbph + prostate$svi + prostate$lcp + prostate$gleason + prostate$pgg45, data = prostate)\n",
    "confint(lmod1, parm = \"prostate$age\", level = 0.95)\n",
    "confint(lmod1, parm = \"prostate$age\", level = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that conifidence intervals and p-values display related information. Because the 95% confidence interval covers 0, we know that the p-value is greater than 0.05. But because the 90% confidence interval does not cover 0, we know the p-value is less than 0.10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) In class, we discussed a reason why conducting several individual hypothesis tests (e.g., t-tests for regression parameters) is problematic. It turns out that computing individual confidence intervals has a similar issue. Instead, we might compute a \"joint confidence region\" for several parameters.  Compute and display the 95% joint confidence region for the parameters associated with age and lbph. Plot the origin on this display. The location of the origin on the display tells us the outcome of certain hypothesis test. State the test and its outcome. \n",
    "\n",
    "The ellipse package and corresponding function should help here. Use the code below (and help files) as a guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\ngACCBAggSIAAggQIIEiAAIIECCBIgID/MgB4KvbfcsAAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# install.packages(\"ellipse\")\n",
    "library(ellipse)\n",
    "#plot(ellipse(NameOfModel,c,type = \"l\") #c is a vector specifying the indices of the desired parameters\n",
    "index = c(4,5)\n",
    "plot(ellipse(lmod1, index, type = \"l\"))\n",
    "points(x = 0, y = 0, pch = 19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the confidence region, we would be testing the hypotheses:\n",
    "\n",
    "$H_0: \\beta_j = 0$  \n",
    "$H_1: \\beta_j \\ne 0$\n",
    "\n",
    "The confidence region contains all the values of $\\mu_0$ that would not be rejected by a t-test. Therefor, because the origin is within the area, we fail to reject the null and assert that the features do not have a statistically significant impact on the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Remove all predictors that are not significant at the $\\alpha = 0.05$ level. Test this model against the original model. Which model is preferred?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Res.Df</th><th scope=col>RSS</th><th scope=col>Df</th><th scope=col>Sum of Sq</th><th scope=col>F</th><th scope=col>Pr(&gt;F)</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>93       </td><td>47.78486 </td><td>NA       </td><td>      NA </td><td>      NA </td><td>       NA</td></tr>\n",
       "\t<tr><td>88       </td><td>44.16302 </td><td> 5       </td><td>3.621837 </td><td>1.443387 </td><td>0.2167334</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       " Res.Df & RSS & Df & Sum of Sq & F & Pr(>F)\\\\\n",
       "\\hline\n",
       "\t 93        & 47.78486  & NA        &       NA  &       NA  &        NA\\\\\n",
       "\t 88        & 44.16302  &  5        & 3.621837  & 1.443387  & 0.2167334\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Res.Df | RSS | Df | Sum of Sq | F | Pr(>F) | \n",
       "|---|---|\n",
       "| 93        | 47.78486  | NA        |       NA  |       NA  |        NA | \n",
       "| 88        | 44.16302  |  5        | 3.621837  | 1.443387  | 0.2167334 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Res.Df RSS      Df Sum of Sq F        Pr(>F)   \n",
       "1 93     47.78486 NA       NA        NA        NA\n",
       "2 88     44.16302  5 3.621837  1.443387 0.2167334"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lmodRed = lm(prostate$lpsa ~ prostate$lcavol + prostate$lweight + prostate$svi, data = prostate)\n",
    "anova(lmodRed, lmod1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the data that was not significant at the $\\alpha = 0.05$ level (age, lbph, lcp, gleason, pgg45), we created a new model. When we tested this model with ANOVA, we found that it had a p-value of 0.217, which is greater than 0.05, so we reject the null and assert that the full model has a statistically significant difference that the reduced model so we should not get rid of all of those predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem B.2\n",
    "\n",
    "This [link](https://www.colorado.edu/amath/sites/default/files/attached-files/advertising.txt) contains advertising data. This dataset contains, in thousands of dollars, TV, Radio, and Newspaper budgets for 200 different markets along with the Sales, in thousands of units, for each market.\n",
    "\n",
    "#### (a) Load the dataset using the link above and split the data into a training set and a test set, as done in the previous homework. (Remove the variable X.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>TV</th><th scope=col>radio</th><th scope=col>newspaper</th><th scope=col>sales</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>230.1</td><td>37.8 </td><td>69.2 </td><td>22.1 </td></tr>\n",
       "\t<tr><td> 44.5</td><td>39.3 </td><td>45.1 </td><td>10.4 </td></tr>\n",
       "\t<tr><td> 17.2</td><td>45.9 </td><td>69.3 </td><td> 9.3 </td></tr>\n",
       "\t<tr><td>151.5</td><td>41.3 </td><td>58.5 </td><td>18.5 </td></tr>\n",
       "\t<tr><td>180.8</td><td>10.8 </td><td>58.4 </td><td>12.9 </td></tr>\n",
       "\t<tr><td>  8.7</td><td>48.9 </td><td>75.0 </td><td> 7.2 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " TV & radio & newspaper & sales\\\\\n",
       "\\hline\n",
       "\t 230.1 & 37.8  & 69.2  & 22.1 \\\\\n",
       "\t  44.5 & 39.3  & 45.1  & 10.4 \\\\\n",
       "\t  17.2 & 45.9  & 69.3  &  9.3 \\\\\n",
       "\t 151.5 & 41.3  & 58.5  & 18.5 \\\\\n",
       "\t 180.8 & 10.8  & 58.4  & 12.9 \\\\\n",
       "\t   8.7 & 48.9  & 75.0  &  7.2 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "TV | radio | newspaper | sales | \n",
       "|---|---|---|---|---|---|\n",
       "| 230.1 | 37.8  | 69.2  | 22.1  | \n",
       "|  44.5 | 39.3  | 45.1  | 10.4  | \n",
       "|  17.2 | 45.9  | 69.3  |  9.3  | \n",
       "| 151.5 | 41.3  | 58.5  | 18.5  | \n",
       "| 180.8 | 10.8  | 58.4  | 12.9  | \n",
       "|   8.7 | 48.9  | 75.0  |  7.2  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  TV    radio newspaper sales\n",
       "1 230.1 37.8  69.2      22.1 \n",
       "2  44.5 39.3  45.1      10.4 \n",
       "3  17.2 45.9  69.3       9.3 \n",
       "4 151.5 41.3  58.5      18.5 \n",
       "5 180.8 10.8  58.4      12.9 \n",
       "6   8.7 48.9  75.0       7.2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = read.csv(\"Advertising.csv\")\n",
    "# Name of column to be dropped\n",
    "dropX = \"X\"\n",
    "data = data[, !(names(data) %in% dropX)]\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for random numbers\n",
    "set.seed(99)\n",
    "# Sample size is 80% of the number of rows\n",
    "sampleSize = floor(0.8 * nrow(data))\n",
    "# Get random row indexes from the data set\n",
    "randIndexes = sample(seq_len(nrow(data)), size = sampleSize)\n",
    "# Create training set from rows with the random indexes. Make test set everything else.\n",
    "training = data[randIndexes, ]\n",
    "test = data[-randIndexes, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Fit the full MLR model. Which variables are statistically significant at the 5% level? Discuss the difference between statistical and practical significance in this context. Also, the estimate for newspaper is negative. Do you actually think that sales *suffer* as a result of newspaper advertising?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = sales ~ TV + radio + newspaper, data = training)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-8.6118 -0.6569  0.1975  1.2522  2.7601 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  2.9574591  0.3444175   8.587 8.59e-15 ***\n",
       "TV           0.0466668  0.0015979  29.206  < 2e-16 ***\n",
       "radio        0.1825387  0.0098530  18.526  < 2e-16 ***\n",
       "newspaper   -0.0007881  0.0064732  -0.122    0.903    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 1.74 on 156 degrees of freedom\n",
       "Multiple R-squared:  0.8989,\tAdjusted R-squared:  0.897 \n",
       "F-statistic: 462.4 on 3 and 156 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lmod = lm(sales ~ TV + radio + newspaper, data = training)\n",
    "summary(lmod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the p-values in the above summary, the TV and radio variables are statistically significant because their p-values are lower than the significance level. Newspaper has a p-value of 0.903 which is much higher than the significance, so so must reject the null and say that it is not statistically significant. Although the data says that newspaper is statistically insignificant, it may still lead to other practical benefits in other ways that are not accounted for in the data, such as visibility and audience. The reason that the newspaper estimate is negative is most likely because it's very close to zero, meaning it has no influence on the result, but some variance in the data slightly shifted it to be negative. Practically, it is unlikely that creating newspapers would decrease sales. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Imagine that, in your test set, you don't have any response measurements. Compute predictions--including 95% *prediction* intervals--of sales for all measurements in your test set. Print the prediction MSE and the first five prediction intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>fit</th><th scope=col>lwr</th><th scope=col>upr</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>3</th><td>12.084039</td><td> 8.561592</td><td>15.60649 </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>13.320209</td><td> 9.835785</td><td>16.80463 </td></tr>\n",
       "\t<tr><th scope=row>8</th><td>12.135424</td><td> 8.679796</td><td>15.59105 </td></tr>\n",
       "\t<tr><th scope=row>14</th><td> 8.889091</td><td> 5.422603</td><td>12.35558 </td></tr>\n",
       "\t<tr><th scope=row>26</th><td>15.849677</td><td>12.359050</td><td>19.34030 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & fit & lwr & upr\\\\\n",
       "\\hline\n",
       "\t3 & 12.084039 &  8.561592 & 15.60649 \\\\\n",
       "\t5 & 13.320209 &  9.835785 & 16.80463 \\\\\n",
       "\t8 & 12.135424 &  8.679796 & 15.59105 \\\\\n",
       "\t14 &  8.889091 &  5.422603 & 12.35558 \\\\\n",
       "\t26 & 15.849677 & 12.359050 & 19.34030 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | fit | lwr | upr | \n",
       "|---|---|---|---|---|\n",
       "| 3 | 12.084039 |  8.561592 | 15.60649  | \n",
       "| 5 | 13.320209 |  9.835785 | 16.80463  | \n",
       "| 8 | 12.135424 |  8.679796 | 15.59105  | \n",
       "| 14 |  8.889091 |  5.422603 | 12.35558  | \n",
       "| 26 | 15.849677 | 12.359050 | 19.34030  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   fit       lwr       upr     \n",
       "3  12.084039  8.561592 15.60649\n",
       "5  13.320209  9.835785 16.80463\n",
       "8  12.135424  8.679796 15.59105\n",
       "14  8.889091  5.422603 12.35558\n",
       "26 15.849677 12.359050 19.34030"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "2.17858142802154"
      ],
      "text/latex": [
       "2.17858142802154"
      ],
      "text/markdown": [
       "2.17858142802154"
      ],
      "text/plain": [
       "[1] 2.178581"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = predict(lmod, newdata = test)\n",
    "predIntervals = predict(lmod, newdata = test, interval = \"prediction\")\n",
    "head(predIntervals, 5)\n",
    "# Calculate the MSE = (1/n)*sum(y-yHat)^2\n",
    "mean((test[,4] - as.numeric(preds))^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE/RSS of the prediction is 2.179."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Add some polynomial terms to the model. Specifically, add $TV^2$ and $radio^2$ to the model. To do this, you'll need to use the I() function: I(predictor^2). Comment on the significance of these terms. Assume $\\alpha = 0.05$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = sales ~ TV + radio + newspaper + I(TV^2) + I(radio^2), \n",
       "    data = training)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-7.3234 -0.8082  0.0752  1.0235  3.2554 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  1.823e+00  4.765e-01   3.826 0.000189 ***\n",
       "TV           7.824e-02  5.678e-03  13.778  < 2e-16 ***\n",
       "radio        1.324e-01  3.316e-02   3.993 0.000101 ***\n",
       "newspaper    1.736e-04  5.934e-03   0.029 0.976693    \n",
       "I(TV^2)     -1.113e-04  1.944e-05  -5.727 5.21e-08 ***\n",
       "I(radio^2)   1.149e-03  6.784e-04   1.693 0.092447 .  \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 1.577 on 154 degrees of freedom\n",
       "Multiple R-squared:  0.918,\tAdjusted R-squared:  0.9153 \n",
       "F-statistic: 344.8 on 5 and 154 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lmod2 = lm(sales ~ TV + radio + newspaper + I(TV^2) + I(radio^2), data = training)\n",
    "summary(lmod2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The added features are surprisingly signficant even though they are basesd on previous data. The $TV^2$ term has a very low p-value, by far low enough to be deemed statistically significant given normal tests. The $radio^2$ term was not deemed statistically significant at 95% confidence, but would be at 90% confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Is it surprising that $R^2$ increased from the model in (c) to the model in (d)? Explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It should not be surprising because of two reasons. First, we know that increasing the number of features increases the $R^2$ value (or at worst keeps it the same) so by adding two more predictors, some other variation in the data was somewhat explained. Secondly, the new features are based on data from the original predictors, meaning that they more correlated than say random values. Both of these reasons explain why the value of $R^2$ inceased from **(c)** to **(d)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (f) Conduct a test (not just individual t-tests) to decide whether you should keep the quadratic terms in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Res.Df</th><th scope=col>RSS</th><th scope=col>Df</th><th scope=col>Sum of Sq</th><th scope=col>F</th><th scope=col>Pr(&gt;F)</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>156         </td><td>472.3231    </td><td>NA          </td><td>      NA    </td><td>      NA    </td><td>          NA</td></tr>\n",
       "\t<tr><td>154         </td><td>383.1527    </td><td> 2          </td><td>89.17041    </td><td>17.92006    </td><td>1.007437e-07</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       " Res.Df & RSS & Df & Sum of Sq & F & Pr(>F)\\\\\n",
       "\\hline\n",
       "\t 156          & 472.3231     & NA           &       NA     &       NA     &           NA\\\\\n",
       "\t 154          & 383.1527     &  2           & 89.17041     & 17.92006     & 1.007437e-07\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Res.Df | RSS | Df | Sum of Sq | F | Pr(>F) | \n",
       "|---|---|\n",
       "| 156          | 472.3231     | NA           |       NA     |       NA     |           NA | \n",
       "| 154          | 383.1527     |  2           | 89.17041     | 17.92006     | 1.007437e-07 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Res.Df RSS      Df Sum of Sq F        Pr(>F)      \n",
       "1 156    472.3231 NA       NA        NA           NA\n",
       "2 154    383.1527  2 89.17041  17.92006 1.007437e-07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anova(lmod, lmod2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the p-value of the partial F-test is $1.007*10^{-7}< 0.05$, we reject the null and assert that the initial model is insuffienct and should use the model with the quadratic terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (g) Redo part (c) for the model with the quadratic terms. How do the predicted MSEs compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>fit</th><th scope=col>lwr</th><th scope=col>upr</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>3</th><td>11.644807</td><td> 8.428899</td><td>14.86071 </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>13.902990</td><td>10.732890</td><td>17.07309 </td></tr>\n",
       "\t<tr><th scope=row>8</th><td>12.656876</td><td> 9.503430</td><td>15.81032 </td></tr>\n",
       "\t<tr><th scope=row>14</th><td> 9.466606</td><td> 6.318100</td><td>12.61511 </td></tr>\n",
       "\t<tr><th scope=row>26</th><td>15.177423</td><td>11.985447</td><td>18.36940 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & fit & lwr & upr\\\\\n",
       "\\hline\n",
       "\t3 & 11.644807 &  8.428899 & 14.86071 \\\\\n",
       "\t5 & 13.902990 & 10.732890 & 17.07309 \\\\\n",
       "\t8 & 12.656876 &  9.503430 & 15.81032 \\\\\n",
       "\t14 &  9.466606 &  6.318100 & 12.61511 \\\\\n",
       "\t26 & 15.177423 & 11.985447 & 18.36940 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | fit | lwr | upr | \n",
       "|---|---|---|---|---|\n",
       "| 3 | 11.644807 |  8.428899 | 14.86071  | \n",
       "| 5 | 13.902990 | 10.732890 | 17.07309  | \n",
       "| 8 | 12.656876 |  9.503430 | 15.81032  | \n",
       "| 14 |  9.466606 |  6.318100 | 12.61511  | \n",
       "| 26 | 15.177423 | 11.985447 | 18.36940  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   fit       lwr       upr     \n",
       "3  11.644807  8.428899 14.86071\n",
       "5  13.902990 10.732890 17.07309\n",
       "8  12.656876  9.503430 15.81032\n",
       "14  9.466606  6.318100 12.61511\n",
       "26 15.177423 11.985447 18.36940"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1.69265294281693"
      ],
      "text/latex": [
       "1.69265294281693"
      ],
      "text/markdown": [
       "1.69265294281693"
      ],
      "text/plain": [
       "[1] 1.692653"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predQuad = predict(lmod2, newdata = test)\n",
    "predQuadIntervals = predict(lmod2, newdata = test, interval = \"prediction\")\n",
    "head(predQuadIntervals, 5)\n",
    "# Calculate the MSE = (1/n)*sum(y-yHat)^2\n",
    "mean((test[,4] - as.numeric(predQuad))^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE of the model with the quadratic terms was $1.693$ which is lower than the MSE of $2.179$ for the model without the quadratic terms. This also implies that the second model explains more variance in the data than the first model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
